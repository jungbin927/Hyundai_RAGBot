import streamlit as st
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import pickle

# ëª¨ë¸ ë¡œë”©
model = SentenceTransformer("paraphrase-MiniLM-L6-v2")

# ì €ì¥ëœ ì²­í¬ ë¡œë”©
with open("chunked_texts.pkl", "rb") as f:
    chunked_texts = pickle.load(f)

# FAISS ì¸ë±ìŠ¤ ë¡œë”©
index = faiss.read_index("vector_db2.index")

# ê²€ìƒ‰ í•¨ìˆ˜
def search_query(query, k=3):
    query_embedding = model.encode(query).reshape(1, -1)
    distances, indices = index.search(query_embedding, k)
    return distances, indices

# Streamlit UI
st.title("ğŸ“„ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ")

# ê²€ìƒ‰ ì…ë ¥
query = st.text_input("ğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")

if query:
    distances, indices = search_query(query)
    st.write("ğŸ“Œ ê²€ìƒ‰ ê²°ê³¼:")

    for i, idx in enumerate(indices[0]):
        st.write(f"**ìœ ì‚¬ë„:** {distances[0][i]:.4f}")
        st.write(f"**ë‚´ìš©:** {chunked_texts[idx]}")
        st.write("---")

